---
title: "New York Times COVID-19 data visualization"
author: Anton Antonov
date: 2020-03-30
output: 
  html_notebook:
    fig_width: 6
    fig_hight: 4
    fig_align: "center"
---

```{r, echo=FALSE}
library(Hmisc)
library(highcharter)
library(dplyr)
library(ggplot2)
library(leaflet)
library(d3heatmap)
library(ParetoPrincipleAdherence)
library(lubridate)
library(forecast)
```

# Introduction

The purpose of this notebook is to give data locations, data ingestion code, and code for rudimentary analysis and visualization of COVID-19 data provided by New York Times, [NYT1]. 

The following steps are taken:

- Ingest data

  - Take COVID-19 data from The New York Times, based on reports from state and local health agencies, [NYT1].

  - Take USA counties records data (FIPS codes, geo-coordinates, populations), [WRI1].

- Merge the data.

- Make data summaries and related plots.

- Make corresponding geo-plots.

- Do “out of the box” time series forecast.

- Analyze fluctuations around time series trends.

Note that other, older repositories with COVID-19 data exist, like, [JH1, VK1].

**Remark:** The time series section is done for illustration purposes only. The forecasts there should not be taken seriously.

# Preliminary defintions

From the help of `tolower`:

```{r}
capwords <- function(s, strict = FALSE) {
    cap <- function(s) paste(toupper(substring(s, 1, 1)),
                  {s <- substring(s, 2); if(strict) tolower(s) else s},
                             sep = "", collapse = " " )
    sapply(strsplit(s,  split = " "), cap, USE.NAMES = !is.null(names(s)))
}
```

# Import data

## NYTimes USA states data

```{r}
if( !exists("dfNYDataStates") ) {
  dfNYDataStates <- read.csv( "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv", 
                              colClasses = c("character", "character", "character", "integer", "integer"), 
                              stringsAsFactors = FALSE )
  colnames(dfNYDataStates) <- capwords(colnames(dfNYDataStates))
}
head(dfNYDataStates)
```

```{r}
dfNYDataStates$DateObject <- as.POSIXct(dfNYDataStates$Date)
```

```{r}
summary(as.data.frame(unclass(dfNYDataStates), stringsAsFactors = TRUE))
```

Summary by state:

```{r, eval=FALSE}
by( data = as.data.frame(unclass(dfNYDataStates)), INDICES = dfNYDataStates$State, FUN = summary )
```

Alternative summary:

```{r, eval=FALSE}
Hmisc::describe(dfNYDataStates)
```


## NYTimes USA counties data

```{r}
if(!exists("dfNYDataCounties") ) {
  dfNYDataCounties <- read.csv( "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv", 
                                colClasses = c("character", "character", "character", "character", "integer", "integer"),
                                stringsAsFactors = FALSE )
  colnames(dfNYDataCounties) <- capwords(colnames(dfNYDataCounties))
}
head(dfNYDataCounties)
```

```{r}
dfNYDataCounties$DateObject <- as.POSIXct(dfNYDataCounties$Date)
```

```{r}
summary(as.data.frame(unclass(dfNYDataCounties), stringsAsFactors = TRUE))
```

## US county records

```{r}
if(!exists("dfUSACountyData")){
  dfUSACountyData <- read.csv( "https://raw.githubusercontent.com/antononcube/SystemModeling/master/Data/dfUSACountyRecords.csv", 
                               colClasses = c("character", "character", "character", "character", "integer", "numeric", "numeric"),
                               stringsAsFactors = FALSE )
}
head(dfUSACountyData)
```

```{r}
summary(as.data.frame(unclass(dfUSACountyData), stringsAsFactors = TRUE))
```

# Merge data

```{r}
dsNYDataCountiesExtended <- 
  dfNYDataCounties %>% 
  dplyr::inner_join( dfUSACountyData %>% dplyr::select_at( .vars = c("FIPS", "Lat", "Lon", "Population") ), by = c( "Fips" = "FIPS" ) )
dsNYDataCountiesExtended
```


# Basic data analysis

```{r}
ParetoPlotForColumns( dsNYDataCountiesExtended, c("Cases", "Deaths"), scales = "free" )
```

# Geo-histogram

## ggplot2

Note that in the plots in this sub-section we filter out Hawaii and Alaska.

```{r}
ggplot2::ggplot(dsNYDataCountiesExtended[ dsNYDataCountiesExtended$Lon > -130, c("Lat", "Lon", "Cases")]) +
  ggplot2::geom_point( ggplot2::aes(x = Lon, y = Lat, fill = log10(Cases)), alpha = 0.01, size = 0.5, color = "blue" ) + 
  ggplot2::coord_quickmap()
```

## Leaflet

***The most recent versions of `leaflet` RStudio are having problems with the visualization below.***
 
```{r}
cf <- colorBin( palette = "Reds", domain = log10(dsNYDataCountiesExtended$Cases), bins = 10 )
```

```{r, eval=FALSE}
m <- 
  leaflet( dsNYDataCountiesExtended[, c("Lat", "Lon", "Cases")] ) %>%
  addTiles() %>% 
  addCircleMarkers( ~Lon, ~Lat, radius = ~ log10(Cases), fillColor = ~ cf(log10(Cases)), color = ~ cf(log10(Cases)), fillOpacity = 0.8, stroke = FALSE, popup = ~Cases )
m
```

```{r}
dsNYDataCountiesExtended
```

# Heat-map plots

An alternative of the geo-visualization is to use a heat-map plot.


## Cases

Make a heat-map plot by sorting the rows of the cross-tabulation matrix (that correspond to states):

```{r}
matSDC <- xtabs( Cases ~ State + Date, dfNYDataStates, sparse = TRUE)
d3heatmap::d3heatmap( log10(matSDC+1), cellnote = as.matrix(matSDC), scale = "none", dendrogram = "row", colors = "Blues") #, theme = "dark")
```


## Deaths

Cross-tabulate states with dates over deaths and plot:


```{r}
matSDD <- xtabs( Deaths ~ State + Date, dfNYDataStates, sparse = TRUE)
d3heatmap::d3heatmap( log10(matSDD+1), cellnote = as.matrix(matSDD), scale = "none", dendrogram = "row", colors = "Blues") #, theme = "dark")
```

# Time series analysis

In this section we do simple "forecasting" (not a serious attempt).

Make time series data frame in long form:

```{r}
dfQuery <- 
  dfNYDataStates %>% 
  dplyr::group_by( Date, DateObject ) %>% 
  dplyr::summarise_at( .vars = c("Cases", "Deaths"), .funs = sum )
dfQueryLongForm <- tidyr::pivot_longer( dfQuery, cols = c("Cases", "Deaths"), names_to = "Variable", values_to = "Value")
head(dfQueryLongForm)
```

Plot the time series:

```{r}
ggplot(dfQueryLongForm) +
  geom_line( aes( x = DateObject, y = log10(Value) ) ) +
  facet_wrap( ~Variable, ncol = 1 )
```

## Cases

Fit using ARIMA:

```{r}
fit <- forecast::auto.arima( dfQuery$Cases )
fit
```

Plot "forecast":

```{r}
plot( forecast::forecast(fit, h = 20) )
grid(nx = NULL, ny = NULL, col = "lightgray", lty = "dotted")
```

## Deaths

Fit with ARIMA:

```{r}
fit <- forecast::auto.arima( dfQuery$Deaths )
fit
```

Plot "forecast":

```{r}
plot( forecast::forecast(fit, h = 20) )
grid(nx = NULL, ny = NULL, col = "lightgray", lty = "dotted")
```

# Fluctuations

We want to see does the time series data have fluctuations around its trends and estimate the distributions of those fluctuations. 
(Knowing those distributions some further studies can be done.)

This can be efficiently using the software monad `QRMon`, [AAp2, AA1]. Here we load the `QRMon` package:

```{r}
#devtools::install_github(repo = "antononcube/QRMon-R")
library(QRMon)
```

## Fluctuations presence

Here we plot the consecutive differences of the cases and deaths:

```{r}
dfQueryLongForm <- 
  dfQueryLongForm %>% 
  dplyr::group_by( Variable ) %>% 
  dplyr::arrange( DateObject ) %>% 
  dplyr::mutate( Difference = c(0, diff(Value) ) ) %>% 
  dplyr::ungroup()
ggplot(dfQueryLongForm) +
  geom_line( aes( x = DateObject, y = Difference ) ) +
  facet_wrap( ~Variable, ncol = 1, scales = "free_y" )
```

From the plots we see that time series are not monotonically increasing, and there are non-trivial fluctuations in the data.


## Absolute and relative errors distributions

Here we take interesting part of the cases data:

```{r}
dfQueryLongForm2 <- 
  dfQueryLongForm %>% 
  dplyr::filter( difftime( DateObject, as.POSIXct("2020-05-01")) >= 0 ) %>% 
  dplyr::mutate( Regressor = as.numeric(DateObject, origin = "1900-01-01") )
```


Here we specify a `QRMon` workflow that rescales the data, 
fits a B-spline curve to get the trend, 
and finds the absolute and relative errors (residuals, fluctuations) around that trend:

```{r}
qrObj <- 
  QRMonUnit(dfQueryLongForm2 %>% dplyr::filter( Variable == "Cases") %>% dplyr::select( Regressor, Value) ) %>% 
  QRMonRescale(regressorAxisQ = F, valueAxisQ = T) %>% 
  QRMonEchoDataSummary %>% 
  QRMonQuantileRegression( df = 16, probabilities = 0.5 )
```


Here we plot the fit:

```{r}
qrObj <- qrObj %>% QRMonPlot(datePlotQ = T)
```

Here we plot absolute errors:

```{r}
qrObj <- qrObj %>% QRMonErrorsPlot(relativeErrorsQ = F)
```

Here we plot relative errors:

```{r}
qrObj <- qrObj %>% QRMonErrorsPlot(relativeErrorsQ = T)
```

```{r}
dfErrs <- (qrObj %>% QRMonErrors(relativeErrorsQ = F) %>% QRMonTakeValue)[[1]]
quantile(dfErrs$Error, probs = seq(0,1,0.1))
```

```{r}
hist(x = dfErrs$Error, breaks = 60)
```

